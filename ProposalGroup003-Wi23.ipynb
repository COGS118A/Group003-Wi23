{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Project Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Angkitha Anguraj\n",
    "- Andres Villegas\n",
    "- Hieu Pham\n",
    "- Sujal Nahata\n",
    "- Denny Yoo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "As time progresses, scientists and civilians alike are growing concerned by the increased frequency of earthquakes. Since earthquakes are a product of built-up tension between tectonic plates, they are often described as hard to predict. However, we believe utilizing what we have learned about supervised learning in combination with past earthquake data will help us magnitude of future earthquakes. This project aims to predict the magnitude of future earthquakes using machine learning techniques; we will use linear regression, regression decision trees, and feedforward neural networks. The dataset utilized is a public dataset from Kaggle that contains significant earthquakes from 1965-2016. We trained these models to describe our earthquake features in relation to the magnitude and predict magnitudes of future earthquakes, ultimately providing us insights into the relationship between earthquake features and magnitudes. This will help us prevent future earthquakes-related catastrophes. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The National Earthquake Information Center (NEIC) is responsible for determining the location and magnitude of significant earthquakes worldwide and disseminating this information to relevant organizations and the general public<a name=\"usgs\"></a>[<sup>[1]</sup>](#usgsnote). Since 1965, the NEIC has been maintaining a comprehensive earthquake database, which includes information on earthquakes with a magnitude of 5.5 or higher. This database serves as a crucial resource for scientific research and aids in earthquake prediction<a name=\"usgs\"></a>[<sup>[1]</sup>](#usgsnote)<a name=\"neic\"></a>[<sup>[2]</sup>](#neicnote).The NEIC relies on a variety of technologies to detect and locate earthquakes, including seismometers, GPS, and satellite imagery2. Seismometers detect ground motion caused by earthquakes and are capable of detecting earthquakes that occur anywhere on the planet<a name=\"neic\"></a>[<sup>[2]</sup>](#neicnote). GPS technology can detect deformations in the Earth's crust caused by tectonic activity and can help scientists predict future earthquakes2. Satellite imagery can also provide information on changes in the Earth's surface, which may indicate the occurrence of an earthquake<a name=\"neic\"></a>[<sup>[2]</sup>](#neicnote).\n",
    "Earthquake prediction is of utmost importance, as it can help to minimize the damage and loss of life caused by these natural disasters<a name=\"wef\"></a>[<sup>[3]</sup>](#wefnote). Seismologists and geologists have been studying earthquakes for many years, and detecting and reporting them accurately and promptly is a critical part of their work. The NEIC utilizes several techniques to determine the location and magnitude of earthquakes, including analyzing seismic waves and signals detected by seismometers<a name=\"usgs\"></a>[<sup>[1]</sup>](#usgsnote). In recent years, advances in seismometer technology and data processing techniques have allowed for more precise measurements of seismic signals and faster processing of earthquake data<a name=\"wef\"></a>[<sup>[3]</sup>](#wefnote).\n",
    "The NEIC's earthquake database has been instrumental in identifying patterns and trends in earthquake activity, which can help in predicting future earthquakes<a name=\"usgs\"></a>[<sup>[1]</sup>](#usgsnote). The ability to predict earthquakes accurately can aid in emergency management and disaster response, potentially saving many lives and minimizing damage to infrastructure<a name=\"wef\"></a>[<sup>[3]</sup>](#wefnote).\n",
    "Overall, earthquake research remains a critical area of study, and ongoing efforts to improve earthquake detection, reporting, and prediction will help to minimize the impact of these natural disasters on people and communities worldwide<a name=\"wef\"></a>[<sup>[3]</sup>](#wefnote).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "As the number and intensity of earthquakes has increased, it has become increasingly important to predict the magnitude of future earthquakes to determine whether there are earthquake-related catastrophes in our near future. The goal of our project is to predict the magnitude of future earthquakes; in doing so, we can prepare emergency supplies to those affected and prevent large scale loss of life.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset can be accessed at this link: https://www.kaggle.com/datasets/usgs/earthquake-database\n",
    "\n",
    "\n",
    "The data was compiled by the United States Geological Survey (USGS), pulling from information provided by the National Earthquake Information Center (NEIC). It focuses on earthquakes that were recorded at 5.5 magnitude or higher from 1965 to 2016. \n",
    "There are over 23,000 data points with 21 different variables in the original dataset. However, the cleaned and prepared dataset consists of 7286 observations and 10 variables.\n",
    "\n",
    "\n",
    "These variables include: latitude, longitude, depth, depth seismic stations, magnitude, magnitude seismic station, azimuthal gap, horizontal distance, root mean square, and grid location.\n",
    "\n",
    "\n",
    "An observation will include data for each of these variables.\n",
    "\n",
    "\n",
    "The critical feature variables will be: depth, depth seismic stations, magnitude, magnitude seismic station, azimuthal gap, horizontal distance, root mean square (a measurement of seismic waves), and grid location. Since all of these variables, in exception to grid location, have continuous numerical values, they are left in their raw form. Grid location is categorical and refers to the latitude-longitude section where each earthquake occurred. The critical classification variable will be magnitude. This is also numeric.\n",
    "\n",
    "\n",
    "Cleaning was required to remove unnecessary columns for variables like ID and source. This is because the values for these variables were either identical across all observations or were obviously irrelevant for predicting magnitudes. Additionally, observations without values for some of the variables or NaN values were removed because they cannot be used in a holistic model. Finally, a new variable, grid location, was made using the input of each observation’s latitude and longitude and fitting it in a categorical grid. For each entry of grid location, the letter represents the latitude boundary and the number represents the longitude boundary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Depth Seismic Stations</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Magnitude Seismic Stations</th>\n",
       "      <th>Azimuthal Gap</th>\n",
       "      <th>Horizontal Distance</th>\n",
       "      <th>Root Mean Square</th>\n",
       "      <th>Grid Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.039500</td>\n",
       "      <td>-113.777333</td>\n",
       "      <td>6.00</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>335.00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.179833</td>\n",
       "      <td>-116.103000</td>\n",
       "      <td>10.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.00</td>\n",
       "      <td>0.6012</td>\n",
       "      <td>0.3300</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.416000</td>\n",
       "      <td>-118.370000</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.40</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34.416000</td>\n",
       "      <td>-118.370000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>328.50</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.3240</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.416000</td>\n",
       "      <td>-118.370000</td>\n",
       "      <td>6.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.00</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>38.391700</td>\n",
       "      <td>-118.894100</td>\n",
       "      <td>12.30</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.60</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.47</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1898</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>38.377700</td>\n",
       "      <td>-118.895700</td>\n",
       "      <td>8.80</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>48.58</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>E3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7283</th>\n",
       "      <td>36.917900</td>\n",
       "      <td>140.426200</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.00</td>\n",
       "      <td>0.9920</td>\n",
       "      <td>1.5200</td>\n",
       "      <td>E11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7284</th>\n",
       "      <td>-9.028300</td>\n",
       "      <td>118.663900</td>\n",
       "      <td>79.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>3.5530</td>\n",
       "      <td>1.4300</td>\n",
       "      <td>C10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7285</th>\n",
       "      <td>37.397300</td>\n",
       "      <td>141.410300</td>\n",
       "      <td>11.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>428.0</td>\n",
       "      <td>97.00</td>\n",
       "      <td>0.6810</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>E11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7286 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Latitude   Longitude  Depth  Depth Seismic Stations  Magnitude  \\\n",
       "0     31.039500 -113.777333   6.00                    13.0       6.35   \n",
       "1     33.179833 -116.103000  10.00                    15.0       6.60   \n",
       "2     34.416000 -118.370000   8.95                     0.0       6.60   \n",
       "3     34.416000 -118.370000   6.00                     0.0       5.80   \n",
       "4     34.416000 -118.370000   6.00                     0.0       5.80   \n",
       "...         ...         ...    ...                     ...        ...   \n",
       "7281  38.391700 -118.894100  12.30                    40.0       5.60   \n",
       "7282  38.377700 -118.895700   8.80                    33.0       5.50   \n",
       "7283  36.917900  140.426200  10.00                     0.0       5.90   \n",
       "7284  -9.028300  118.663900  79.00                     0.0       6.30   \n",
       "7285  37.397300  141.410300  11.94                     0.0       5.50   \n",
       "\n",
       "      Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
       "0                            4.0         335.00               0.0000   \n",
       "1                            0.0         128.00               0.6012   \n",
       "2                            0.0         123.40               0.0000   \n",
       "3                            0.0         328.50               0.3136   \n",
       "4                            0.0         360.00               0.3136   \n",
       "...                          ...            ...                  ...   \n",
       "7281                        18.0          42.47               0.1200   \n",
       "7282                        18.0          48.58               0.1290   \n",
       "7283                         0.0          91.00               0.9920   \n",
       "7284                         0.0          26.00               3.5530   \n",
       "7285                       428.0          97.00               0.6810   \n",
       "\n",
       "      Root Mean Square Grid Location  \n",
       "0               0.6000            E3  \n",
       "1               0.3300            E3  \n",
       "2               0.2490            E3  \n",
       "3               0.3240            E3  \n",
       "4               0.0050            E3  \n",
       "...                ...           ...  \n",
       "7281            0.1898            E3  \n",
       "7282            0.2187            E3  \n",
       "7283            1.5200           E11  \n",
       "7284            1.4300           C10  \n",
       "7285            0.9100           E11  \n",
       "\n",
       "[7286 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Clean data to remove unnecessary entries and columns\n",
    "data = pd.read_csv('database.csv')\n",
    "data = data[data['Type'] == 'Earthquake']\n",
    "data = data.loc[data['Azimuthal Gap'].notnull()]\n",
    "data = data.fillna(0)\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.drop(labels=['Magnitude Error','Date','Time','Depth Error','Horizontal Error','ID','Source'],axis=1)\n",
    "data = data.drop(labels=['Type','Location Source','Magnitude Type','Magnitude Source','Status'],axis=1)\n",
    "\n",
    "# Create coordinate grid boundaries labels\n",
    "latitude_bins = [-90,-60,-30,0,30,60,90]\n",
    "longitude_bins = [-180,-150,-120,-90,-60,-30,0,30,60,90,120,150,180]\n",
    "latitude_labels = ['A','B','C','D','E','F']\n",
    "longitude_labels = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "\n",
    "# Categorize earthquakes by their grid location\n",
    "data['Grid Location_Lat'] = pd.cut(data['Latitude'],latitude_bins,labels=latitude_labels)\n",
    "data['Grid Location_Long'] = pd.cut(data['Longitude'],longitude_bins,labels=longitude_labels)\n",
    "data['Grid Location'] = data[['Grid Location_Lat','Grid Location_Long']].apply(\"\".join,axis=1)\n",
    "data = data.drop(labels=['Grid Location_Lat','Grid Location_Long'],axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Model\n",
    "\n",
    "In order to better understand our data and have a model to compare our results to, our group utilized Kaggle’s “Code” feature to look through past Kaggle users’ projects. We chose to focus on user Jia Yi’s project on “Predicting Earthquakes with Neural Networks”. They utilized only the date, time, latitude, longitude, depth, and magnitude features of the dataset. They first plotted the affected areas utilizing Matplotlib’s basemap tool and Python’s built in datetime library. Then, they began to split their data. Their X features were latitude, longitude, and time while their y features were depth and magnitude. Using the Keras deep learning API, they instantiated their model and utilized GridSearchCV in a method similar to what we performed in class to tune their hyperparameters. Afterwards, they used the sequential model within Keras to fit their model and derive their accuracy. Their final accuracy amounted to 0.98. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "After receiving feedback from instructors, we decided it would be best to predict only the magnitude of future earthquakes utilizing three models: a linear regression, a regression tree, and a neural network. We chose not to predict other features as the models we studied in class equip us to predict one feature per model. \n",
    "\n",
    "In order to better visualize where earthquakes occur, we converted the longitude and latitude coordinates featured in our dataset into grid locations (analogous to a chess board). We would graph the earthquakes on this grid and utilize the grid coordinate as one of our features. \n",
    "\n",
    "Since magnitudes are an integral in interpreting the danger of earthquakes and are continuous numerical values, we chose to use linear regression; it has the ability to accurately model relationships and predict continuous numerical values. In this case, the features of our model would be the grid coordinate, depth, and azimuthal gap. Using these, we will predict the magnitude as our data point. In order to test the accuracy of this model, we will use mean squared error.\n",
    "\n",
    "On the other hand, we plan on using a regression decision tree. This model is similar to linear regression. Its only difference is that it uses decision partitioning to make its regression. The variables we’ll feed into the decision tree will stay the same as the previous model. Each of these will act as a split for the model. A regression decision tree model is appropriate for our project as it’s good for predicting a singular numerical value. We will then use cross validation to check the accuracy of our model’s results. \n",
    "\n",
    "Finally, after researching, we decided to use feedforward neural networks featured in PyTorch as our neural network model. Since predicting magnitude is a regression based problem and our data is tabular in nature a feedforward neural network works best. We do not need to use a CNN as they’re typically used for image processing or data with spatial relationships. RNNs are off the table as they aren’t applicable to tabular data. Again, the features remain the same as the previous models. Since the size of our dataset is big, we aim to create a model using 40-50% of our dataset. We will train our neural network and fit it to our split dataset. To validate the accuracy of our neural network, we will calculate the loss/error for our batches of data and use functions similar to those within discussion lab eight to calculate the final accuracy. \n",
    "\n",
    "To first clean our data, we will utilize Pandas. To create the aforementioned grid coordinates and graph our data, we will need to import Matplotlib and Seaborn. In addition, given that we mainly utilize regression models, we will need to import Numpy, Scikit-Learn, and PyTorch (and the necessary functions and libraries). All these in conjunction with one another will help us predict the magnitude of future earthquakes and validate the accuracy of our predictions. We will finalize whichever model produces the highest accuracy. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Since one of the models we are using is a linear regression model, the most appropriate evaluation metric to use for this is mean squared error. Since the predictions of our model are continuous values, this will give us a quantitative overview of how far off the actual values are from the predicted values.\n",
    "\n",
    "mean squared error = $\\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y_i})^2 =\\frac{1}{n}\\sum_{i=1}^{n}(y_i-mx_i+b)^2,\\\\$\n",
    "where $mx+b$ is the linear regression model with weight vector m and constant vector b.\n",
    "\n",
    "In addition, we will utilize k-fold cross validation to verify the accuracy of our decision tree results. Cross validation works in that we split our data into chunks and run our decision tree model on all but a specific split number of chunks. These chunks then become the set that we test on; we then run our model as many times as there chunks as we use each chunk to test. We then compare our tests and graph our results to see which split number produced the best results. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy\n",
    "\n",
    "We believe that everything in our research process, from data retrieval to predictive modeling, will  be conducted ethically. Firstly, when making generalizations about future earthquakes that may happen around the world, it is important to have data that is sufficiently representative of all earthquake prone areas around the world. Otherwise, data that is concentrated on certain earthquakes in only a few locations or during a small period of time would be heavily biased and may lead to severe miscalculations for other geographical areas. To address this, we use data from every significant earthquake that has occurred on Earth between 1965 and 2016. Furthermore, all the data from this dataset were collected by researchers on behalf of the National Earthquake Information Center. These researchers had governmental permission to collect and publicly report data from these earthquake sites. Thus, there is no privacy breach involved in the data collection process. The most important concern with our research is the unintended consequences it may have. If the model proves to perform poorly in the real world, it may unnecessarily lead to earthquake paranoia in some areas while undermining the likelihood of earthquakes happening in other areas, leading to underpreparedness. We understand that our model will be far from perfect or comprehensive enough to make real-time predictions. As such, we will create our model for purely educational purposes and do not intend to publicize our findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations \n",
    "\n",
    "* If a teammate has any problems completing their work or making it to meetings, they must communicate it with the rest of the team during a meeting or on our team Discord server.\n",
    "* During each meeting, we will delegate tasks and provide constructive feedback of each others’ work to efficiently finish the project.\n",
    "* After completing individually assigned work, we will conduct a collective project review on the day of each milestone/section deadline to ensure quality.\n",
    "* If any group conflict or individual difficulty arises, we should do our best to help each other and create additional meetings if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/17  |  3 PM |  Brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/19  |  2 PM |  Look through data set, brainstorm any questions, review project proposal requirements | Delegate project proposal tasks, work on timeline together, decide future meeting dates | \n",
    "| 2/26  | 2 PM  | Finish project proposal and submit through GitHub  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 3/5  | 2 PM  | Import & Wrangle Data ,do some EDA | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 3/11  | 12 PM  | Finalize wrangling/EDA; Begin programming for project | Discuss/edit project code; Complete project |\n",
    "| 3/13  | 2 PM  | Complete analysis; Draft results/conclusion/discussion | Discuss/edit full project |\n",
    "| 3/19  | 2 PM  | Finish individual review of the project | Turn in Final Project  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name = \"usgsnote\"></a> 1.[^](#usgs): \"National Earthquake Information Center (NEIC).\" U.S. Geological Survey, https://www.usgs.gov/programs/earthquake-hazards/national-earthquake-information-center-neic<br>\n",
    "<a name = \"neicnote\"></a> 2.[^](#neic)“NEIC - the National Earthquake Information Center” U.S. Geological Survey. (n.d.). Earthquake Hazards Program. ScienceBase. https://www.sciencebase.gov/catalog/item/505a613ee4b0c8380cd71885<br>\n",
    "<a name = \"wefnote\"></a> 3.[^](#wef)\"The science of earthquake prediction explained.\" World Economic Forum, 15 Aug. 2016, https://www.weforum.org/agenda/2016/08/the-science-of-earthquake-prediction-explained/<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
